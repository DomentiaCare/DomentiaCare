package com.example.domentiacare.assistant

import android.content.Context
import android.content.Intent
import android.net.Uri
import android.os.Bundle
import android.speech.RecognitionListener
import android.speech.RecognizerIntent
import android.speech.SpeechRecognizer
import android.util.Log
import android.widget.Toast
import com.example.domentiacare.MyApplication
import com.example.domentiacare.service.androidtts.TTSServiceManager
import kotlinx.coroutines.*
import java.util.*

class AIAssistant(
    private val context: Context,
    private val onScheduleAction: (action: String, details: String) -> Unit,
    private val onStateChanged: (() -> Unit)? = null // ğŸ†• ìƒíƒœ ë³€ê²½ ì½œë°± ì¶”ê°€
) {

    private var speechRecognizer: SpeechRecognizer? = null
    private var isListening = false
    private var isRecognizing = false
    private var isAnalyzing = false // ğŸ†• Llama ë¶„ì„ ì¤‘ ìƒíƒœ ì¶”ê°€
    private var isRetrying = false
    private var isTTSPlaying = false
    private var pendingSpeechRecognition = false


    //í•´ë‹¹ ë‚´ìš©ì€ ë³´í˜¸ìë‚˜ í™˜ìì˜ ì „í™”ë²ˆí˜¸ë¡œ ëŒ€ì²´í•´ì•¼í•¨. (DBì—ì„œ ì •ë³´ê°€ì ¸ì™€ì„œ ì—°ê²°í•´ì•¼í•  ë¶€ë¶„)
    private val contacts = mapOf(
        "caregiver" to "010-1234-5678",
        "patient" to "010-9876-5432",
        "hospital" to "02-123-4567",
        "clinic" to "02-234-5678",
        "pharmacy" to "02-345-6789",
        "emergency" to "119"
    )

    init {
        TTSServiceManager.init(context) {
            Log.d("AIAssistant", "TTS initialization completed")
            //ttsì •ìƒì‘ë™ í…ŒìŠ¤íŠ¸ (ì´ì¢…ë²”)
            //speakKorean("ìŒì„± ì„œë¹„ìŠ¤ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")
        }
    }

    /**
     * Activate AI Assistant (when floating button is clicked)
     */
    fun activateAssistant() {
        Log.d("AIAssistant", "ğŸ”§ activateAssistant() entry: isRecognizing=$isRecognizing, isListening=$isListening, isTTSPlaying=$isTTSPlaying")

        when {
            isRecognizing -> {
                // Currently recognizing â†’ stop recognition
                Log.d("AIAssistant", "ğŸ›‘ Recognition in progress - stopping recognition")
                stopSpeechRecognition()
            }
            isListening -> {
                // Waiting â†’ start speech recognition (only when TTS is not playing)
                Log.d("AIAssistant", "ğŸ¤ Waiting state detected - attempting to start speech recognition")
                startSpeechRecognitionSafe()
            }
            else -> {
                Log.d("AIAssistant", "ğŸš€ Inactive state detected - starting activation")
                // Inactive â†’ activate and start speech recognition
                isListening = true
                Log.d("AIAssistant", "âœ… isListening = true set")

                // Set to start speech recognition after TTS completion
                pendingSpeechRecognition = true
                speakKorean("ë„¤, ë§ì”€í•˜ì„¸ìš”.") {
                    // Start speech recognition in TTS completion callback
                    Log.d("AIAssistant", "ğŸ”Š TTS completed - starting speech recognition")
                    if (pendingSpeechRecognition && isListening && !isRecognizing) {
                        startSpeechRecognitionSafe()
                    }
                    pendingSpeechRecognition = false
                    // ğŸ†• TTS ì™„ë£Œ í›„ì—ë„ UI ì—…ë°ì´íŠ¸
                    onStateChanged?.invoke()
                }
            }
        }

        Log.d("AIAssistant", "ğŸ activateAssistant() completed: isRecognizing=$isRecognizing, isListening=$isListening, isTTSPlaying=$isTTSPlaying")
    }

    /**
     * Safe speech recognition start (checking TTS playback)
     */
    private fun startSpeechRecognitionSafe() {
        if (isTTSPlaying) {
            Log.w("AIAssistant", "âš ï¸ TTS is playing, postponing speech recognition start")
            // Wait briefly and retry after TTS completion
            CoroutineScope(Dispatchers.Main).launch {
                delay(500) // Retry after 0.5 seconds
                if (!isTTSPlaying && isListening && !isRecognizing) {
                    startSpeechRecognition()
                }
            }
            return
        }

        // Ensure we're on the main thread
        CoroutineScope(Dispatchers.Main).launch {
            startSpeechRecognition()
        }
    }

    /**
     * Start STT (Speech-to-Text) - Must be called from Main Thread
     */
    private fun startSpeechRecognition() {
        if (isRecognizing) {
            Log.d("AIAssistant", "âš ï¸ Already recognizing speech")
            return
        }

        if (isTTSPlaying) {
            Log.w("AIAssistant", "âš ï¸ Cannot start speech recognition while TTS is playing")
            return
        }

        // Check STT availability
        if (!SpeechRecognizer.isRecognitionAvailable(context)) {
            Log.e("AIAssistant", "âŒ STT not available on this device")
            speakKorean("ì´ ê¸°ê¸°ì—ì„œëŠ” ìŒì„± ì¸ì‹ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            resetState()
            return
        }

        try {
            // Clean up existing SpeechRecognizer
            speechRecognizer?.destroy()

            // Create Intent for English STT
            val intent = Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH)
            intent.putExtra(RecognizerIntent.EXTRA_LANGUAGE_MODEL, RecognizerIntent.LANGUAGE_MODEL_FREE_FORM)
            intent.putExtra(RecognizerIntent.EXTRA_LANGUAGE, "en-US") // English
            intent.putExtra(RecognizerIntent.EXTRA_PREFER_OFFLINE, false) // Prefer online for better accuracy

            // Create SpeechRecognizer (must be on main thread)
            speechRecognizer = SpeechRecognizer.createSpeechRecognizer(context)
            speechRecognizer?.setRecognitionListener(object : RecognitionListener {
                override fun onResults(results: Bundle?) {
                    val matches = results?.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION)
                    val resultText = matches?.firstOrNull() ?: "No result"

                    Log.d("AIAssistant", "âœ… STT result: '$resultText'")

                    // STT ì™„ë£Œ, ë¶„ì„ ì‹œì‘ ìƒíƒœë¡œ ë³€ê²½
                    isRecognizing = false
                    isAnalyzing = true
                    Log.d("AIAssistant", "ğŸ”„ State changed: isRecognizing=false, isAnalyzing=true")

                    // ğŸ†• UIì— ìƒíƒœ ë³€ê²½ ì•Œë¦¼
                    onStateChanged?.invoke()

                    if (resultText != "No result" && resultText.trim().length >= 2) {
                        // Proceed with Llama analysis
                        analyzeWithLlama(resultText.trim())
                    } else {
                        Log.w("AIAssistant", "âš ï¸ Invalid STT result")
                        speakKorean("ìŒì„±ì„ ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”.")
                        resetState()
                    }
                }

                override fun onError(error: Int) {
                    Log.e("AIAssistant", "âŒ STT error occurred: $error")

                    // STT ì˜¤ë¥˜ ì‹œ ìƒíƒœ ì •ë¦¬
                    isRecognizing = false
                    isAnalyzing = false

                    when (error) {
                        7 -> { // ERROR_NO_MATCH
                            if (!isRetrying) {
                                isRetrying = true
                                speakKorean("ìŒì„±ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•©ë‹ˆë‹¤.") {
                                    // Retry after TTS completion
                                    CoroutineScope(Dispatchers.Main).launch {
                                        delay(1000) // Wait 1 additional second
                                        if (isListening && !isRecognizing && !isTTSPlaying) {
                                            startSpeechRecognition()
                                        }
                                        isRetrying = false
                                    }
                                }
                            } else {
                                speakKorean("ìŒì„± ì¸ì‹ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                                resetState()
                            }
                        }
                        9 -> { // ERROR_INSUFFICIENT_PERMISSIONS
                            speakKorean("ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.")
                            resetState()
                        }
                        else -> {
                            speakKorean("ìŒì„± ì¸ì‹ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                            resetState()
                        }
                    }
                }

                // Required methods
                override fun onReadyForSpeech(params: Bundle?) {
                    Log.d("AIAssistant", "ğŸ¤ Speech recognition ready")
                }
                override fun onBeginningOfSpeech() {
                    Log.d("AIAssistant", "ğŸ—£ï¸ Speech input started")
                    // ğŸ†• ìŒì„± ì…ë ¥ ì‹œì‘ ì‹œì—ë„ UI ì—…ë°ì´íŠ¸
                    onStateChanged?.invoke()
                }
                override fun onRmsChanged(rmsdB: Float) {}
                override fun onBufferReceived(buffer: ByteArray?) {}
                override fun onEndOfSpeech() {
                    Log.d("AIAssistant", "ğŸ›‘ Speech input ended")
                    // onResultsê°€ í˜¸ì¶œë˜ì§€ ì•Šì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ì—¬ê¸°ì„œëŠ” ìƒíƒœ ë³€ê²½í•˜ì§€ ì•ŠìŒ
                }
                override fun onPartialResults(partialResults: Bundle?) {}
                override fun onEvent(eventType: Int, params: Bundle?) {}
            })

            // Start listening
            speechRecognizer?.startListening(intent)
            isRecognizing = true

            Log.d("AIAssistant", "ğŸ¤ STT started (English mode)")

        } catch (e: Exception) {
            Log.e("AIAssistant", "âŒ STT start failed: ${e.message}", e)
            speakKorean("ìŒì„± ì¸ì‹ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            resetState()
        }
    }

    private fun stopSpeechRecognition() {
        try {
            speechRecognizer?.stopListening()
            isRecognizing = false
            isAnalyzing = false // ğŸ†• ì¤‘ì§€ ì‹œ ë¶„ì„ ìƒíƒœë„ ì´ˆê¸°í™”
            Log.d("AIAssistant", "ğŸ›‘ Speech recognition stopped")
        } catch (e: Exception) {
            Log.e("AIAssistant", "âŒ Failed to stop speech recognition: ${e.message}", e)
            resetState()
        }
    }

    /**
     * Analyze English commands with Llama
     */
    private fun analyzeWithLlama(userInput: String) {
        Log.d("AIAssistant", "ğŸ§  Llama analysis started: '$userInput'")

        speakKorean("ëª…ë ¹ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤.")

        CoroutineScope(Dispatchers.IO).launch {
            try {
                val llamaManager = MyApplication.llamaServiceManager

                // English-focused prompt
                val prompt = """
                    User Input: "$userInput"
                    
                    Analyze the English input above and respond with ONLY ONE of these keywords:
                    
                    TOMORROW - tomorrow, tomorrow's schedule, what's tomorrow, tomorrow plan
                    TODAY - today, today's schedule, what's today, today plan, what am I doing today
                    CALL_CAREGIVER - call caregiver, call family, call guardian, call mom, call dad, phone caregiver
                    CALL_PATIENT - call patient, phone patient, call elderly
                    FIND_PATIENT - find patient, locate patient, where is patient, patient location
                    FIND_CAREGIVER - find caregiver, locate caregiver, where is caregiver, caregiver location
                    UNKNOWN - everything else not mentioned above
                    
                    IMPORTANT: Respond with ONLY the keyword. No additional text.
                    
                    Examples:
                    - "What's tomorrow's plan?" â†’ TOMORROW
                    - "Tell me today's schedule" â†’ TODAY  
                    - "Call my caregiver" â†’ CALL_CAREGIVER
                    - "Where is my dad?" â†’ FIND_CAREGIVER
                    - "Find the patient" â†’ FIND_PATIENT
                    - "What's the weather?" â†’ UNKNOWN
                """.trimIndent()

                val llamaResponse = llamaManager.sendQueryBlocking(prompt)
                Log.d("AIAssistant", "ğŸ”¤ Llama keyword response: '$llamaResponse'")

                withContext(Dispatchers.Main) {
                    executeCommand(llamaResponse, userInput)
                }

            } catch (e: Exception) {
                Log.e("AIAssistant", "âŒ Llama analysis failed: ${e.message}", e)
                withContext(Dispatchers.Main) {
                    speakKorean("ëª…ë ¹ì„ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                    resetState()
                }
            }
        }
    }

    /**
     * Execute command based on Llama keyword response
     */

    //í•´ë‹¹ í•¨ìˆ˜ì—ì„œ ê° ëª…ë ¹ì–´ì— ë§ê²Œ í™”ë©´ ì´ë™ ë˜ëŠ” ë‚´ìš©ì´ êµ¬í˜„ë˜ì–´ì•¼í•¨.
    private fun executeCommand(llamaResponse: String, originalQuestion: String) {
        // ë¶„ì„ ì™„ë£Œ
        isAnalyzing = false
        Log.d("AIAssistant", "ğŸ”„ State changed: isAnalyzing=false (analysis completed)")

        // ğŸ†• UIì— ìƒíƒœ ë³€ê²½ ì•Œë¦¼
        onStateChanged?.invoke()

        try {
            val keyword = llamaResponse.trim().uppercase()
            Log.d("AIAssistant", "ğŸ¯ Command to execute: '$keyword' (original: '$originalQuestion')")

            when {
                keyword.contains("TOMORROW") -> {
                    speakKorean("ë‚´ì¼ ì¼ì •ì„ í™•ì¸í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.")
                    onScheduleAction("check", "tomorrow") // -> ì´ê±´ ì˜ë¯¸ ìˆëŠ”ì§€ ëª¨ë¥´ê² ìŒ (ì´ì¢…ë²”)
                    //ì—¬ê¸°ì— ë‚´ì¼ ì¼ì •ì„ ë“±ë¡í•˜ëŠ” ë‚´ìš© ì‚½ì…í•˜ê¸° (ì´ì¢…ë²”)
                }

                keyword.contains("TODAY") -> {
                    speakKorean("ì˜¤ëŠ˜ ì¼ì •ì„ í™•ì¸í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.")
                    onScheduleAction("check", "today")
                    //ì—¬ê¸°ì— ì˜¤ëŠ˜ ì¼ì •ì„ ë“±ë¡í•˜ëŠ” ë‚´ìš© ì‚½ì…í•˜ê¸° (ì´ì¢…ë²”)
                }

                keyword.contains("CALL_CAREGIVER") -> {
                    speakKorean("ë³´í˜¸ìì—ê²Œ ì „í™”ë“œë¦¬ê² ìŠµë‹ˆë‹¤.")
                    makePhoneCall("caregiver", "caregiver")
                    //ì—¬ê¸°ì— ë³´í˜¸ì ì „í™”ë²ˆí˜¸ë¡œ ì „í™”í•˜ëŠ” ë‚´ìš© ì‚½ì…í•˜ê¸° (ì´ì¢…ë²”)
                }

                keyword.contains("CALL_PATIENT") -> {
                    speakKorean("í™˜ìì—ê²Œ ì „í™”ë“œë¦¬ê² ìŠµë‹ˆë‹¤.")
                    makePhoneCall("patient", "patient")
                    //ì—¬ê¸°ì— í™˜ì ì „í™”ë²ˆí˜¸ë¡œ ì „í™”í•˜ëŠ” ë‚´ìš© ì‚½ì…í•˜ê¸° (ì´ì¢…ë²”)
                }

                keyword.contains("FIND_PATIENT") -> {
                    speakKorean("í™˜ì ìœ„ì¹˜ë¥¼ í™•ì¸í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.")
                    onScheduleAction("find", "patient")
                    //ì—¬ê¸°ì— í™˜ì ìœ„ì¹˜ë¡œ ê¸¸ì•ˆë‚´ í•˜ëŠ” ë‚´ìš© ì‚½ì…í•˜ê¸° (ì´ì¢…ë²”)
                }

                keyword.contains("FIND_CAREGIVER") -> {
                    speakKorean("ë³´í˜¸ì ìœ„ì¹˜ë¥¼ í™•ì¸í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.")
                    onScheduleAction("find", "caregiver")
                    //ì—¬ê¸°ì— ë³´í˜¸ì ìœ„ì¹˜ë¡œ ê¸¸ì•ˆë‚´ í•˜ëŠ” ë‚´ìš© ì‚½ì…í•˜ê¸° (ì´ì¢…ë²”)
                }

                else -> {
                    Log.d("AIAssistant", "âš ï¸ Unsupported command: '$keyword'")
                    speakKorean("ì£„ì†¡í•©ë‹ˆë‹¤. ì•„ì§ ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª…ë ¹ì…ë‹ˆë‹¤. ì¼ì • í™•ì¸, ì „í™” ê±¸ê¸°, ë˜ëŠ” ìœ„ì¹˜ ì°¾ê¸°ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.")
                }
            }

        } catch (e: Exception) {
            Log.e("AIAssistant", "âŒ Command execution failed: ${e.message}", e)
            speakKorean("ëª…ë ¹ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        }

        resetState()

        onStateChanged?.invoke() // ğŸ†• ìƒíƒœ ë³€ê²½ ì•Œë¦¼
    }

    /**
     * Make phone call
     */
    private fun makePhoneCall(contactKey: String, contactName: String) {
        try {
            val phoneNumber = contacts[contactKey]
            if (phoneNumber != null) {
                val callIntent = Intent(Intent.ACTION_CALL).apply {
                    data = Uri.parse("tel:$phoneNumber")
                    flags = Intent.FLAG_ACTIVITY_NEW_TASK
                }
                context.startActivity(callIntent)
                Log.d("AIAssistant", "ğŸ“ Making call: $contactName ($phoneNumber)")
            } else {
                speakKorean("ì—°ë½ì²˜ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                Log.e("AIAssistant", "âŒ Contact not found: $contactKey")
            }
        } catch (e: Exception) {
            Log.e("AIAssistant", "âŒ Failed to make phone call: ${e.message}", e)
            speakKorean("ì „í™”ë¥¼ ê±¸ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        }
    }

    /**
     * Safe TTS voice output (with state management)
     */
    private fun speakKorean(text: String, onComplete: (() -> Unit)? = null) {
        isTTSPlaying = true
        Log.d("AIAssistant", "ğŸ”Š TTS started: '$text', isTTSPlaying=true")

        TTSServiceManager.speak(text) {
            // TTS completion callback
            isTTSPlaying = false
            Log.d("AIAssistant", "ğŸ”Š TTS completed: '$text', isTTSPlaying=false")
            onComplete?.invoke()
        }
    }

    /**
     * Stop assistant
     */
    fun stopListening() {
        Log.d("AIAssistant", "ğŸ›‘ Assistant stopped by user request")

        if (isRecognizing) {
            stopSpeechRecognition()
        }

        speakKorean("ìŒì„± ì¸ì‹ì„ ì¤‘ì§€í–ˆìŠµë‹ˆë‹¤.")
        resetState()
    }

    /**
     * Reset state
     */
    private fun resetState() {
        isListening = false
        isRecognizing = false
        isAnalyzing = false // ğŸ†• ë¶„ì„ ìƒíƒœë„ ì´ˆê¸°í™”
        isRetrying = false
        pendingSpeechRecognition = false
        // isTTSPlaying is only set to false in TTS completion callback

        try {
            speechRecognizer?.destroy()
            speechRecognizer = null
        } catch (e: Exception) {
            Log.e("AIAssistant", "âŒ Failed to clean up SpeechRecognizer: ${e.message}", e)
        }

        Log.d("AIAssistant", "ğŸ”„ Assistant state reset")

        // ğŸ†• UIì— ìƒíƒœ ë³€ê²½ ì•Œë¦¼
        onStateChanged?.invoke()
    }

    /**
     * Check assistant state
     */
    fun isActive(): Boolean = isListening || isRecognizing || isAnalyzing // ğŸ†• ë¶„ì„ ì¤‘ë„ í™œì„± ìƒíƒœ

    /**
     * Check if currently recording
     */
    fun isCurrentlyRecording(): Boolean {
        val result = isRecognizing
        Log.d("AIAssistant", "ğŸ” isCurrentlyRecording(): $result")
        return result
    }

    /**
     * ğŸ†• Check if currently analyzing with Llama
     */
    fun isCurrentlyAnalyzing(): Boolean {
        val result = isAnalyzing
        Log.d("AIAssistant", "ğŸ” isCurrentlyAnalyzing(): $result")
        return result
    }

    /**
     * Check if waiting (activated but not recognizing)
     */
    fun isWaiting(): Boolean {
        val result = isListening && !isRecognizing && !isAnalyzing
        Log.d("AIAssistant", "ğŸ” isWaiting(): $result (isListening=$isListening, isRecognizing=$isRecognizing, isAnalyzing=$isAnalyzing)")
        return result
    }

    /**
     * Check if TTS is currently playing
     */
    fun isTTSCurrentlyPlaying(): Boolean = isTTSPlaying

    /**
     * Clean up resources
     */
    fun destroy() {
        Log.d("AIAssistant", "ğŸ§¹ AI Assistant resource cleanup")

        stopListening()
        TTSServiceManager.shutdown()

        try {
            speechRecognizer?.destroy()
            speechRecognizer = null
        } catch (e: Exception) {
            Log.e("AIAssistant", "âŒ Failed to clean up SpeechRecognizer: ${e.message}", e)
        }
    }
}